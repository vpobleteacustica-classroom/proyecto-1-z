{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047d525e",
   "metadata": {},
   "source": [
    "# Proyecto de ACUS 220 Acústica Computacional con Python  \n",
    "\n",
    "### Primer Hito de Entrega  \n",
    "\n",
    "**Integrantes:** Martin Maza, Samantha Espinoza, Esperanza Tejeda, Rudy Richter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce9095",
   "metadata": {},
   "source": [
    "## Objetivos del Proyecto  \n",
    "\n",
    "**Objetivo General:**  \n",
    "- Desarrollar un software capaz de analizar cualquier canción en formato digital y generar automáticamente partituras o tablaturas de guitarra lead, facilitando la práctica y composición para guitarristas de todos los niveles.\n",
    "\n",
    "**Objetivos Específicos:**  \n",
    "- OE1: Implementar un sistema de separación de instrumentos que permita aislar los instrumentos de una canción y obtener sus partituras.\n",
    "\n",
    "- OE2: Desarrollar un algoritmo de reconocimiento de la melodía principal, capaz de identificar las notas que corresponden al instrumento lead y/o a la voz principal de la canción.\n",
    "\n",
    "- OE3: Generar automáticamente las partituras o tablaturas de guitarra lead a partir de la melodía identificada, adaptándolas a un formato legible y reproducible por el usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba83cb",
   "metadata": {},
   "source": [
    "## Estado del Arte \n",
    "\n",
    "En los últimos años, gracias a los avances en la inteligencia artificial y el procesamiento digital de señales, los investigadores han desarrollado diversas técnicas para analizar grabaciones musicales de forma automática. Entre estas destacan los métodos orientados a la identificación de sonidos específicos mediante el análisis de sus frecuencias (Caropresse & Montoya, 2014; Rosner & Kostek, 2018; Vázquez Robledo, Lizárraga Morales, & López Ramírez, 2024), así como los sistemas de transcripción automática de música (Automatic Music Transcription, AMT), cuyo objetivo es transformar una señal de audio en notación musical legible por humanos o interpretable por software (Donis del Álamo, 2021; Chieppa, 2024; Julian & Mukund, 2024). Este tipo de investigación ha cobrado especial fuerza desde el año 2020, impulsada por el creciente acceso a modelos de aprendizaje profundo y a bases de datos musicales de libre disponibilidad (Klangio, s. f.; López-Rincón, Starostenko, & Ayala-San Martín, 2018).\n",
    "\n",
    "En este mismo contexto, han surgido los sistemas de recuperación de información musical (Music Information Retrieval, MIR), un campo de investigación emergente orientado al desarrollo de herramientas de software capaces de extraer, analizar y recuperar información relevante desde archivos de audio (Vázquez Robledo, 2024; Rosner & Kostek, 2018). Estos sistemas combinan técnicas de procesamiento digital de señales, aprendizaje automático (Machine Learning, ML) e inteligencia artificial, lo que permite abordar diversas problemáticas asociadas con la organización y caracterización de la música digital. Entre sus principales aplicaciones se encuentran la identificación de intérpretes o artistas, la detección de canciones, la clasificación por género musical, el análisis de ritmo y tempo, el reconocimiento de emociones musicales y la identificación de instrumentos (Vázquez Robledo, Lizárraga Morales, & López Ramírez, 2024; Rosner & Kostek, 2018). Esta última área, la detección automática de instrumentos musicales, constituye el foco principal del presente proyecto.\n",
    "\n",
    "Para el proyecto propuesto, estas dos técnicas serían importantes ya que permiten descomponer la canción en todos sus elementos musicales (voz, guitarra, bajo, teclado, percusión, etc.) para así utilizar las fuentes sonoras que sean más relevantes, mezclándolas y haciendo una única pieza que combine todos los elementos esenciales de la composición (Donis del Álamo, 2021; Chieppa, 2024). De esta forma, se podrá posteriormente hacer una transcripción de la canción en forma de tablatura para guitarra. La idea es que musicalmente sea atractiva, de modo que la tablatura generada no refleje las notas de la canción original, sino que también mantenga coherencia, dinámica y expresividad, generando una versión que sea agradable de escuchar y fiel a su esencia musical (Julian & Mukund, 2024; López-Rincón, Starostenko, & Ayala-San Martín, 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc17aa5",
   "metadata": {},
   "source": [
    "## Materiales y Métodos  \n",
    "\n",
    "### Materiales  \n",
    "- Listar los datos, grabaciones, sensores o librerías de Python que se usarán.  \n",
    "\n",
    "### Metodología  \n",
    "Describir paso a paso cómo se abordará el problema.  \n",
    "\n",
    "**Ejemplo plan de trabajo:**  \n",
    "\n",
    "| Actividad                        | Responsable(s)   | Fecha estimada |\n",
    "|----------------------------------|-----------------|----------------|\n",
    "| Revisión bibliográfica           | Grupo completo  | 10/10/2025     |\n",
    "| Recolección de datos en terreno  | Nombre1         | 20/10/2025     |\n",
    "| Procesamiento de datos en Python | Nombre2         | 30/10/2025     |\n",
    "| Entrenamiento del modelo         | Nombre3         | 15/11/2025     |\n",
    "| Redacción de informe parcial     | Grupo completo  | 25/11/2025     |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb4b2e",
   "metadata": {},
   "source": [
    "## Referencias Bibliográficas  \n",
    "\n",
    "1. Caropresse, G., & Montoya, D. E. A. (2014, noviembre). *Identificación de instrumentos musicales con redes neuronales usando separación de fuentes*. En **Jornadas de Investigación y Encuentro Académico Industrial (JIFI 2014)**, Universidad Central de Venezuela, Caracas, Venezuela. Disponible en ResearchGate: https://www.researchgate.net/publication/275641654_Identificacion_de_Instrumentos_Musicales_con_Redes_Neuronales_Usando_Separacion_de_Fuentes\n",
    "\n",
    "2. Donis del Álamo, J. (2021). *Transcripción musical mediante redes neuronales profundas* (Trabajo de fin de máster). Universidad de Alicante. https://rua.ua.es/bitstream/10045/118065/1/Transcripcion_de_musica_con_redes_neuronales_profundas_Donis_Del_Alamo_Jorge.pdf\n",
    "\n",
    "3. Rosner, A., & Kostek, B. (2018). *Automatic music genre classification based on musical instrument track separation*. **Journal of Intelligent Information Systems, 50**, 363–384. https://doi.org/10.1007/s10844-017-0464-5\n",
    "\n",
    "4. Klangio. (s. f.). *Research*. Recuperado el 6 de octubre de 2025, de https://klang.io/about-us/research\n",
    "\n",
    "5. Vázquez Robledo, A. S., Lizárraga Morales, R. A., & López Ramírez, M. (2024). *Clasificación de instrumentos musicales en audios utilizando coeficientes cepstrales y redes neuronales artificiales*. **Jóvenes en la Ciencia, 33** (Congreso Internacional de Electrónica y Cómputo Aplicado 2024). https://www.jovenesenlaciencia.ugto.mx/index.php/jovenesenlaciencia/article/view/4701\n",
    "\n",
    "6. Vázquez Robledo, A. S. (2024). *Identificación de instrumentos musicales en audios utilizando análisis de señales e inteligencia artificial* (Tesis de maestría, Universidad de Guanajuato). http://repositorio.ugto.mx/bitstream/20.500.12059/13673/3/ALAN_SALOMON_VAZQUEZ_ROBLEDO_TesisMtria24.pdf\n",
    "\n",
    "7. Chieppa, S. (2024). *Automatic guitar transcription using deep neural networks* (Tesis de maestría, Sapienza University of Rome). Publications – MIR/DEI, University of Coimbra. https://mir.dei.uc.pt/publications.html\n",
    "\n",
    "8. López-Rincón, O., Starostenko, O., & Ayala-San Martín, G. (2018). *Algorithmic music composition based on artificial intelligence: A survey*. En 2018 International Conference on Electronics, Communications and Computers (CONIELECOMP) (pp. 187–193). IEEE. https://doi.org/10.1109/CONIELECOMP.2018.8327197\n",
    "\n",
    "9. Julian, A., & Mukund, V. (2024). *Music to score conversion using machine learning*. IEEE. https://ieeexplore.ieee.org/abstract/document/10502423"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
